<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html lang="en-GB" xml:lang="en-GB" xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="content-type" content="text/html; charset=utf-8"/>
    <title>Tokenization and Word Segmentation</title>
    <link rel="icon" href="https://universaldependencies.org/logos/logo-ud.png" type="image/png">
    <link rel="root" href=""/> <!-- for JS -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" type="text/css" href="../../css/jquery-ui-redmond.css"/>
    <link rel="stylesheet" type="text/css" href="../../css/style.css"/>
    <link rel="stylesheet" type="text/css" href="../../css/style-vis.css"/>
    <link rel="stylesheet" type="text/css" href="../../css/hint.css"/>
    <script type="text/javascript" src="../../lib/ext/head.load.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/anchor-js/3.2.2/anchor.min.js"></script>
    <script>document.addEventListener("DOMContentLoaded", function(event) {anchors.add();});</script>
    <!-- Set up this custom Google search at https://programmablesearchengine.google.com/controlpanel/overview?cx=001145188882102106025%3Adl1mehhcgbo
         or try it at https://cse.google.com/cse?cx=001145188882102106025%3Adl1mehhcgbo -->
    <!-- DZ 2021-01-22: I am temporarily hiding the search field to find out whether it slows down loading of the title page.
         DZ 2025-11-18: Turning it on again (the homepage is slow anyway, because of other factors). -->
    <script>
      (function() {
        var cx = '001145188882102106025:dl1mehhcgbo';
        var gcse = document.createElement('script');
        gcse.type = 'text/javascript';
        gcse.async = true;
        gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
        var s = document.getElementsByTagName('script')[0];
        s.parentNode.insertBefore(gcse, s);
      })();
    </script>


  </head>
  <body>
    <div id="main" class="center">

      <div id="hp-header">
        <table width="100%"><tr><td width="50%">
          <span class="header-text"><a href="http://universaldependencies.org/#language-u">home</a></span>

          <span class="header-text"><a href="https://github.com/universaldependencies/docs/edit/pages-source/_u-overview/tokenization.md" target="#">edit page</a></span>
          <span class="header-text"><a href="https://github.com/universaldependencies/docs/issues">issue tracker</a></span>
        </td><td>
          <gcse:search></gcse:search>
        </td></tr></table>
      </div>

      <hr/>

      
      <div class="v2complete">
        This page pertains to UD version 2.
      </div>
      

      <div id="content">
        <noscript>
          <div id="noscript">
            It appears that you have Javascript disabled.
            Please consider enabling Javascript for this page to see the visualizations.
          </div>
        </noscript>

        <!-- The content may include scripts and styles, hence we must load the shared libraries before the content. -->
        <script type="text/javascript">
            console.time('loading libraries');
            var root = '../../'; // filled in by jekyll
            head.js(
                // External libraries
                // DZ: Copied from embedding.html. I don't know which one is needed for what, so I'm currently keeping them all.
                root + 'lib/ext/jquery.min.js',
                root + 'lib/ext/jquery.svg.min.js',
                root + 'lib/ext/jquery.svgdom.min.js',
                root + 'lib/ext/jquery.timeago.js',
                root + 'lib/ext/jquery-ui.min.js',
                root + 'lib/ext/waypoints.min.js',
                root + 'lib/ext/jquery.address.min.js'
            );
        </script>
        <h1 id="tokenization-and-word-segmentation">Tokenization and Word Segmentation</h1>

<p>The UD annotation is based on a lexicalist view of syntax, which means that dependency relations 
hold between <em>words</em>. Hence, morphological features are encoded as properties of words and there is no attempt at
segmenting words into morphemes. However, it is important to note that the basic units of annotation are <em>syntactic</em> 
words (not phonological or orthographic words), which means that we systematically want to split off clitics, as in 
Spanish <em>dámelo</em> = <em>da me lo</em>, and undo contractions, as in French <em>au</em> = <em>à le</em>. We refer to such cases as 
<em>multiword tokens</em> because a single orthographic <em>token</em> corresponds to multiple (syntactic) <em>words</em>.
In exceptional cases, it may be necessary to go in the other direction, and combine several orthographic
tokens into a single syntactic word. Starting from v2 of the UD guidelines, such <em>multitoken words</em> are allowed
for a restricted class of phenomena, such as numerical expressions like <em>20 000</em> and abbreviations like <em>e. g.</em>, 
as long as these phenomena are approved and clearly specified in the language-specific documentation. 
Note, however, that this technique should <em>not</em> be generalized to multiword expressions like <em>in spite of</em> 
and <em>by and large</em> (let alone to more flexible multiword expressions like compounds or particle verbs), which should
instead be annotated using special dependency relations.</p>

<p>Since word segmentation in general is a non-trivial task in many languages, and since the usefulness of tools trained on treebank data ultimately depends on how well the word segmentation can be reproduced for new data, it is important to document the principles of word segmentation for each language.
The nature of this documentation will vary from one language to the next, depending on properties of the language and
the writing system. For languages where word segmentation can be performed by a simple script given white-space and 
punctuation, only the words need to be represented in the treebank. 
For languages not using white-space at all, such as Chinese and Japanese, a complex word segmentation algorithm has 
to be employed, but there is no need to represent the basic character sequence in the treebank since it is completely 
recoverable from the word representation. By contrast, in languages where the mapping between white-space delimited 
<em>tokens</em> and syntactic <em>words</em> is highly ambiguous, such as Arabic and Hebrew, we provide the option of including 
both tokens and words in the treebank using a two-level indexing scheme described in the 
<a href="../../format.html">CoNLL-U format</a> section. 
The morphological and syntactic annotation is only defined at the word level, but a heuristic mapping to the token level
can usually be provided.</p>

<p>Language-specific extensions to this documentation must describe how tokenization and word segmentation has been performed for each language (including references to standard tokenization schemes if any). In addition, it should answer the following questions:</p>

<ul>
  <li>Do spaces regularly occur inside words? (This is only allowed for languages like Vietnamese, where whitespace is used to mark syllable boundaries rather than word boundaries.)</li>
  <li>Do spaces exceptionally occur inside (multitoken) words? If yes, specify exactly in which cases (for example, numbers and abbreviations).</li>
  <li>Does the treebank include (multiword) tokens as well as words? If yes, specify exactly in which cases (for example, clitics and contractions).</li>
</ul>

      </div>

<!-- support for embedded visualizations -->
<script type="text/javascript">
    var root = '../../'; // filled in by jekyll
    head.js(
        // We assume that external libraries such as jquery.min.js have already been loaded outside!
        // (See _layouts/base.html.)

        // brat helper modules
        root + 'lib/brat/configuration.js',
        root + 'lib/brat/util.js',
        root + 'lib/brat/annotation_log.js',
        root + 'lib/ext/webfont.js',
        // brat modules
        root + 'lib/brat/dispatcher.js',
        root + 'lib/brat/url_monitor.js',
        root + 'lib/brat/visualizer.js',

        // embedding configuration
        root + 'lib/local/config.js',
        // project-specific collection data
        root + 'lib/local/collections.js',

        // Annodoc
        root + 'lib/annodoc/annodoc.js',

        // NOTE: non-local libraries
        'https://spyysalo.github.io/conllu.js/conllu.js'
    );

    var webFontURLs = [
//        root + 'static/fonts/Astloch-Bold.ttf',
        root + 'static/fonts/PT_Sans-Caption-Web-Regular.ttf',
        root + 'static/fonts/Liberation_Sans-Regular.ttf'
    ];

    var setupTimeago = function() {
        jQuery("time.timeago").timeago();
    };

    head.ready(function() {
        setupTimeago();

        // mark current collection (filled in by Jekyll)
        Collections.listing['_current'] = 'u-overview';

	// perform all embedding and support functions
	Annodoc.activate(Config.bratCollData, Collections.listing);
    });
</script>


<!-- google analytics -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-55233688-1', 'auto');
  ga('send', 'pageview');

</script>


      <div id="footer">
          <p class="footer-text">&copy; 2014–2024
            <a href="http://universaldependencies.org/introduction.html#contributors" style="color:gray">Universal Dependencies contributors</a>.
            Site powered by <a href="http://spyysalo.github.io/annodoc" style="color:gray">Annodoc</a> and <a href="http://brat.nlplab.org/" style="color:gray">brat</a></p>.
      </div>
    </div>
  </body>
</html>
